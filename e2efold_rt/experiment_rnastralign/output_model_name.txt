model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
model_att.position_embedding_1d
torch.Size([1, 10, 600])
model_att.conv1d1.weight
torch.Size([10, 4, 9])
model_att.conv1d1.bias
torch.Size([10])
model_att.bn1.weight
torch.Size([10])
model_att.bn1.bias
torch.Size([10])
model_att.conv_test_1.weight
torch.Size([10, 60, 1, 1])
model_att.conv_test_1.bias
torch.Size([10])
model_att.bn_conv_1.weight
torch.Size([10])
model_att.bn_conv_1.bias
torch.Size([10])
model_att.conv_test_2.weight
torch.Size([10, 10, 1, 1])
model_att.conv_test_2.bias
torch.Size([10])
model_att.bn_conv_2.weight
torch.Size([10])
model_att.bn_conv_2.bias
torch.Size([10])
model_att.conv_test_3.weight
torch.Size([1, 10, 1, 1])
model_att.conv_test_3.bias
torch.Size([1])
model_att.encoder_layer.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.encoder_layer.self_attn.in_proj_bias
torch.Size([60])
model_att.encoder_layer.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.encoder_layer.self_attn.out_proj.bias
torch.Size([20])
model_att.encoder_layer.linear1.weight
torch.Size([2048, 20])
model_att.encoder_layer.linear1.bias
torch.Size([2048])
model_att.encoder_layer.linear2.weight
torch.Size([20, 2048])
model_att.encoder_layer.linear2.bias
torch.Size([20])
model_att.encoder_layer.norm1.weight
torch.Size([20])
model_att.encoder_layer.norm1.bias
torch.Size([20])
model_att.encoder_layer.norm2.weight
torch.Size([20])
model_att.encoder_layer.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.0.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.0.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.0.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.0.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.0.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.0.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.0.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.1.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.1.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.1.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.1.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.1.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.1.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.1.norm2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_weight
torch.Size([60, 20])
model_att.transformer_encoder.layers.2.self_attn.in_proj_bias
torch.Size([60])
model_att.transformer_encoder.layers.2.self_attn.out_proj.weight
torch.Size([20, 20])
model_att.transformer_encoder.layers.2.self_attn.out_proj.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.linear1.weight
torch.Size([2048, 20])
model_att.transformer_encoder.layers.2.linear1.bias
torch.Size([2048])
model_att.transformer_encoder.layers.2.linear2.weight
torch.Size([20, 2048])
model_att.transformer_encoder.layers.2.linear2.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm1.bias
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.weight
torch.Size([20])
model_att.transformer_encoder.layers.2.norm2.bias
torch.Size([20])
model_att.PE_net.0.weight
torch.Size([50, 111])
model_att.PE_net.0.bias
torch.Size([50])
model_att.PE_net.2.weight
torch.Size([50, 50])
model_att.PE_net.2.bias
torch.Size([50])
model_att.PE_net.4.weight
torch.Size([10, 50])
model_att.PE_net.4.bias
torch.Size([10])
model_pp.s
torch.Size([1])
model_pp.w
torch.Size([1])
model_pp.rho
torch.Size([1])
model_pp.rho_m
torch.Size([600, 600])
model_pp.alpha
torch.Size([1])
model_pp.beta
torch.Size([1])
model_pp.lr_decay_alpha
torch.Size([1])
model_pp.lr_decay_beta
torch.Size([1])
model_pp.rho_net.0.weight
torch.Size([5, 3])
model_pp.rho_net.0.bias
torch.Size([5])
model_pp.rho_net.2.weight
torch.Size([1, 5])
model_pp.rho_net.2.bias
torch.Size([1])
model_pp.rho_pos_net.0.weight
torch.Size([4, 2])
model_pp.rho_pos_net.0.bias
torch.Size([4])
model_pp.rho_pos_net.2.weight
torch.Size([1, 4])
model_pp.rho_pos_net.2.bias
torch.Size([1])
